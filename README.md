<img width="591" height="827" alt="image" src="https://github.com/user-attachments/assets/988e34e5-0068-41f4-a9b7-85176760959d" /># 2025ë…„ í•œì´ìŒ ë“œë¦¼ì—… í”„ë¡œì íŠ¸ : BRIX ğŸ“ - RGB ì¹´ë©”ë¼ì™€ AI ê¸°ë°˜ ê³¼ì¼ ë‹¹ë„ ì˜ˆì¸¡ ë° ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ  (25_HC122)

--- 

## **ğŸ’¡1. í”„ë¡œì íŠ¸ ê°œìš”**

---

**1-1. í”„ë¡œì íŠ¸ ì†Œê°œ**

- í”„ë¡œì íŠ¸ ëª… : RGB ì¹´ë©”ë¼ì™€ AI ê¸°ë°˜ ê³¼ì¼ ë‹¹ë„ ì˜ˆì¸¡ ë° ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ
- í”„ë¡œì íŠ¸ ì •ì˜ : RGB ì¹´ë©”ë¼ì™€ AI ëª¨ë¸(CNN + YOLO)ì„ í™œìš©í•˜ì—¬ ê³¼ì¼ì˜ ë‹¹ë„ë¥¼ ë¹„íŒŒê´´ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³ , Jetson Nano ê¸°ë°˜ ìë™ ë¶„ë¥˜ ì¥ì¹˜ ë° ëª¨ë°”ì¼ ì§ê±°ë˜ í”Œë«í¼ê³¼ ì—°ë™í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ë†ì—… ì„œë¹„ìŠ¤
    
    ![í”„ë¡œì íŠ¸ ì´ë¯¸ì§€](https://github.com/user-attachments/assets/6be524a9-c0c1-48b7-8741-1216298f2768)
    

**1-2. ê°œë°œ ë°°ê²½ ë° í•„ìš”ì„±**

- ê¸°ì¡´ ë‹¹ë„ ì¸¡ì •ì€ ê³ ê°€ ì¥ë¹„(NIR, êµ´ì ˆë‹¹ë„ê³„) í˜¹ì€ íŒŒê´´ì  ë°©ì‹ìœ¼ë¡œ ë†ê°€ ë³´ê¸‰ì´ ì–´ë ¤ì›€
- ì†Œë¹„ìëŠ” ì™¸í˜•ë¿ ì•„ë‹ˆë¼ ë‹¹ë„, ì‹ ì„ ë„ ë“± ê°ê´€ì  í’ˆì§ˆ ë°ì´í„°ë¥¼ ì›í•˜ì§€ë§Œ ì œê³µ ì„œë¹„ìŠ¤ ë¶€ì¡±
- RGB ì¹´ë©”ë¼ + AI ê¸°ìˆ ì„ í™œìš©í•˜ë©´ ì €ë¹„ìš©Â·ë¹„íŒŒê´´Â·ì‹¤ì‹œê°„ ì¸¡ì • ê°€ëŠ¥
- ìƒì‚°ì-ì†Œë¹„ì ê°„ ì‹ ë¢° ê¸°ë°˜ ì§ê±°ë˜ í”Œë«í¼ ìˆ˜ìš” ì¦ê°€

**1-3. í”„ë¡œì íŠ¸ íŠ¹ì¥ì **

- ì €ë¹„ìš© RGB ì¹´ë©”ë¼ ê¸°ë°˜ ë¹„íŒŒê´´ ë‹¹ë„ ì˜ˆì¸¡
- YOLOv5 ê°ì²´ íƒì§€ + CNN íšŒê·€ëª¨ë¸ ê¸°ë°˜ ì‹¤ì‹œê°„ í’ˆì§ˆ ë¶„ì„
- Jetson Nano + ì»¨ë² ì´ì–´ ì‹œìŠ¤í…œì„ í†µí•œ ìë™ ë¶„ë¥˜Â·ì´ì†¡
- í† í° ê¸°ë°˜ ì§ê±°ë˜ í”Œë«í¼ (ë“±ê¸‰ë³„ íŒë§¤ ê¶Œí•œ, ë¦¬ë·°, ì±„íŒ… ê¸°ëŠ¥)

**1-4. ì£¼ìš” ê¸°ëŠ¥**

ğŸ“Œ ì†Œí”„íŠ¸ì›¨ì–´(S/W)
- ê³¼ì¼ ê°ì²´ ì¸ì‹ : YOLOv5 ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë‚´ ê³¼ì¼ íƒì§€ ë° ìœ„ì¹˜ ë¶„í• 
- ë‹¹ë„ ì˜ˆì¸¡ ë° ë“±ê¸‰ ë¶„ë¥˜ : CNN íšŒê·€ ëª¨ë¸ë¡œ Brix ê°’ì„ ì¶”ì •í•˜ê³ , K-Means ê¸°ë°˜ S/A/B/C ìë™ ë“±ê¸‰í™”
- ê±°ë˜ í”Œë«í¼ ì„œë¹„ìŠ¤ : Spring Boot ë°±ì—”ë“œ + React Native ì•±ì„ í†µí•´ ìƒí’ˆ ë“±ë¡, êµ¬ë§¤, ë¦¬ë·° ì‘ì„±, ì‹œì„¸ ê·¸ë˜í”„ ì¡°íšŒ ê°€ëŠ¥
- ì‚¬ìš©ì ê´€ë¦¬ ë° ì¸ì¦ : JWT ê¸°ë°˜ ë¡œê·¸ì¸/íšŒì›ê°€ì…, Redisë¥¼ í†µí•œ Refresh Token ê´€ë¦¬, AWS S3 í”„ë¡œí•„Â·ìƒí’ˆ ì´ë¯¸ì§€ ì €ì¥

ğŸ“Œ í•˜ë“œì›¨ì–´(H/W)
- Jetson Nano ì‹¤ì‹œê°„ ì¶”ë¡  : YOLO + CNN ëª¨ë¸ì„ íƒ‘ì¬í•´ í˜„ì¥ì—ì„œ ì‹¤ì‹œê°„ ê³¼ì¼ íƒì§€ ë° ë‹¹ë„ ì˜ˆì¸¡ ìˆ˜í–‰
- RGB ì¹´ë©”ë¼ ì´¬ì˜ : ê³ ì •í˜• ì¹´ë©”ë¼ ë˜ëŠ” ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ë¥¼ í†µí•´ ê³¼ì¼ ì´ë¯¸ì§€ ì´¬ì˜
- ì»¨ë² ì´ì–´ ë²¨íŠ¸ ì œì–´ : ê³¼ì¼ì„ ìë™ìœ¼ë¡œ ì´ì†¡í•˜ê³ , ë“±ê¸‰ ê²°ê³¼ì— ë”°ë¼ ìœ„ì¹˜ë³„ë¡œ ë¶„ë¥˜
- Arduino Uno + MG90S ì„œë³´ëª¨í„° : Jetson Nanoë¡œë¶€í„° ì „ë‹¬ë°›ì€ S/A/B/C ì‹ í˜¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³¼ì¼ì„ ì§€ì •ëœ êµ¬ì—­ìœ¼ë¡œ ë¶„ë¥˜

**1-5. ê¸°ëŒ€ íš¨ê³¼ ë° í™œìš© ë¶„ì•¼**

ğŸ“Œ ê¸°ëŒ€ íš¨ê³¼
- ë†ê°€ : ìë™ í’ˆì§ˆ ì¸¡ì •ìœ¼ë¡œ ë…¸ë™ë ¥ ì ˆê°, ì†Œë“ ì•ˆì •í™”
- ì†Œë¹„ì : ê°ê´€ì  í’ˆì§ˆ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢° ìˆëŠ” êµ¬ë§¤ ê²°ì •
- ì‚¬íšŒì  íš¨ê³¼ : ìŠ¤ë§ˆíŠ¸ ë†ì—… ë° ë””ì§€í„¸ ìœ í†µ í™œì„±í™”, ì§ê±°ë˜ ë¬¸í™” í™•ì‚°
- ì—°êµ¬ì  í™œìš© : ê³¼ì¼ í’ˆì§ˆ ë¹…ë°ì´í„° ì¶•ì , ìŠ¤ë§ˆíŠ¸íŒœ/ì •ì±… ë°ì´í„° ê¸°ë°˜ í™•ì¥

ğŸ“Œ í™œìš© ë¶„ì•¼
- ë†ì—… ë° ìŠ¤ë§ˆíŠ¸íŒœ : ê³¼ì¼ ë‹¹ë„Â·í’ˆì§ˆ ìë™ ì¸¡ì •, ë°ì´í„° ê¸°ë°˜ ë†ì¥ ìš´ì˜
- ìœ í†µ ë° ì§ê±°ë˜ í”Œë«í¼ : ê³¼í•™ì  ë“±ê¸‰ ê¸°ì¤€ì— ê¸°ë°˜í•œ ì‹ ë¢° ê±°ë˜, ì¤‘ê°„ ë§ˆì§„ ì ˆê°
- í”„ë¦¬ë¯¸ì—„ ì‹œì¥ : S/A ë“±ê¸‰ ê³¼ì¼ì˜ í”„ë¦¬ë¯¸ì—„ ë§ˆì¼€íŒ… ë° ìˆ˜ì¶œìš© ì‹œì¥ ì§„ì¶œ
- ì—°êµ¬ ë° ì •ì±… : ì¥ê¸° í’ˆì§ˆ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸ ë†ì—… ì—°êµ¬ ë° ìœ í†µ ì •ì±… ìˆ˜ë¦½
  
**1-6. ê¸°ìˆ  ìŠ¤íƒ**

- í”„ë¡ íŠ¸ì—”ë“œ : React Native, Expo
- ë°±ì—”ë“œ : Java (Spring Boot), Redis, AWS S3, RDS(MySQL)
- AI/ML : PyTorch, YOLOv5, OpenCV, FastAPI
- DB : MySQL, Redis
- í´ë¼ìš°ë“œ : AWS EC2, Docker
- H/W : Jetson Nano, RGB ì¹´ë©”ë¼, Arduino Uno R3, MG90S ì„œë³´ëª¨í„°, ì»¨ë² ì´ì–´ ë²¨íŠ¸
  
---

## **ğŸ’¡2. íŒ€ì› ì†Œê°œ**

---

| ì‚¬ì§„ | <img width="100" height="170" alt="image" src="https://github.com/user-attachments/assets/3346c8e6-08d4-4a39-84f3-093828dd7701" /> | <img width="100" height="170" alt="image" src="https://github.com/user-attachments/assets/f0a1f1fd-05ba-4281-bba3-f560878108c0"  /> | <img width="100" height="170" alt="image" src="https://github.com/user-attachments/assets/79347fbf-d45c-4f18-a2b5-def33dea79d5" /> | <img width="100" height="170" src="https://github.com/user-attachments/assets/6a89cc36-32c4-4145-ab12-6c0339fbd7c1" /> | <img width="100" height="170" alt="image" src="https://github.com/user-attachments/assets/9e265fb2-dc21-4cb8-a592-6bf13ba1d13c" /> | <img width="100" height="170" alt="image" src="https://github.com/user-attachments/assets/0da0b15f-137f-494a-85f9-721835ec0672" />
" /> |
| ---- | ----- | ----- | ----- | ----- | ----- | ---- |
| íŒ€ì› | íŒ€ì›1 | íŒ€ì›2 | íŒ€ì›3 | íŒ€ì›4 | íŒ€ì›5 | ë©˜í†  |
| ì—­í•  | AI ê°œë°œ | AI ê°œë°œ | ë°±ì—”ë“œ ê°œë°œ | ë°±ì—”ë“œ ê°œë°œ | í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ | í”„ë¡œì íŠ¸ ì´ê´„ |

---

## **ğŸ’¡3. ì‹œìŠ¤í…œ êµ¬ì„±ë„**

---
> 
- ì„œë¹„ìŠ¤ êµ¬ì„±ë„

![ì„œë¹„ìŠ¤ êµ¬ì„±ë„](https://github.com/user-attachments/assets/144ad0fc-9c29-4c74-a2ab-00be34092475)

- ì—”í‹°í‹° ê´€ê³„ë„

![ì—”í‹°í‹° ê´€ê³„ë„](https://github.com/user-attachments/assets/62386e8d-881f-4ca8-8b42-e35f8c829eeb)

---

## **ğŸ’¡4. ì‘í’ˆ ì†Œê°œì˜ìƒ**

---

> [![[2025 í•œì´ìŒ ë“œë¦¼ì—… ê³µëª¨ì „ ì‹œì—° ì˜ìƒ] RGBì¹´ë©”ë¼ì™€ ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•œ ê³¼ì¼ ë‹¹ë„ ì¸¡ì • ì„œë¹„ìŠ¤](https://github.com/user-attachments/assets/e1e84ff0-4696-4299-93a6-c3238927da3c)](https://youtu.be/2iMyMO82c9s?si=YAMznI-zBLoh6I4d)

---

## **ğŸ’¡5. í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ**

---

- ì†ŒìŠ¤ì½”ë“œ ì„¤ëª… : CNN ê¸°ë°˜ì˜ 6ì±„ë„ ì…ë ¥ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì •ì˜í•œ ì½”ë“œì…ë‹ˆë‹¤.

```python
# ===============================
#  RGB + HSV (6ì±„ë„) ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# ===============================
class RGBHSVDataset_Lite(Dataset):
    def __init__(self, csv_file, img_size=None, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_size = img_size
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def _ensure_uint8_hwc(self, img):
        if isinstance(img, torch.Tensor):
            img = img.detach().cpu().permute(1, 2, 0).numpy()
            if img.max() <= 1.0:
                img = (img * 255.0).clip(0, 255)
            img = img.astype(np.uint8)
        else:
            if img.dtype != np.uint8:
                if img.max() <= 1.0:
                    img = (img * 255.0).clip(0, 255).astype(np.uint8)
                else:
                    img = img.clip(0, 255).astype(np.uint8)
        return img

    def __getitem__(self, idx):
        img_path = self.data.iloc[idx, 0]
        brix = float(self.data.iloc[idx, 1])

        # 1) ì´ë¯¸ì§€ ë¡œë“œ (BGR)
        bgr = cv2.imread(img_path)
        if bgr is None:
            raise FileNotFoundError(f"Failed to read image: {img_path}")
        if self.img_size is not None:  
            bgr = cv2.resize(bgr, self.img_size, interpolation=cv2.INTER_AREA)

        # 2) BGR -> RGB
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

        # 3) Albumentations ì¦ê°•
        if self.transform:
            out = self.transform(image=rgb)
            rgb = out["image"]

        # 4) uint8 HWC ë³€í™˜
        rgb = self._ensure_uint8_hwc(rgb)

        # 5) RGB ì •ê·œí™” + HSV
        rgb_f = rgb.astype(np.float32) / 255.0
        hsv   = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV).astype(np.float32)
        hsv[..., 0] /= 179.0
        hsv[..., 1] /= 255.0
        hsv[..., 2] /= 255.0

        # 6) RGB + HSV â†’ (6, H, W)
        combined = np.concatenate([rgb_f, hsv], axis=-1)
        combined = np.transpose(combined, (2, 0, 1))
        image_tensor = torch.from_numpy(combined).float()

        return image_tensor, torch.tensor(brix, dtype=torch.float32)

# ===============================
#   6ì±„ë„ CNN íšŒê·€ ëª¨ë¸
# ===============================
class BrixRegression6CH_Deep(nn.Module):
    def __init__(self):
        super().__init__()

        def conv_block(in_ch, out_ch, p_drop):
            return nn.Sequential(
                nn.Conv2d(in_ch, out_ch, 3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.LeakyReLU(),
                nn.Conv2d(out_ch, out_ch, 3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.LeakyReLU(),
                nn.MaxPool2d(2),
                nn.Dropout(p_drop)
            )

        self.layer1 = conv_block(6, 32, 0.1)
        self.layer2 = conv_block(32, 64, 0.2)
        self.layer3 = conv_block(64, 128, 0.3)
        self.layer4 = conv_block(128, 256, 0.4)

        self.global_pool = nn.AdaptiveAvgPool2d(1)

        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(256, 128),
            nn.LeakyReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.global_pool(x)
        x = self.fc(x)
        return x.squeeze(1)
```
- ì†ŒìŠ¤ì½”ë“œ ì„¤ëª… : ëª¨ë¸ í›ˆë ¨ ì½”ë“œì…ë‹ˆë‹¤.

```python
# ===============================
#   K-Fold í•™ìŠµ ë£¨í”„
# ===============================
def train_kfold(
    csv_file,
    k=5,
    epochs=30,
    batch_size=32,
    lr=1e-3,
    img_size=(128, 128),
    use_augmentation=True,
    patience=10,
    save_dir="./best_model"
):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    os.makedirs(save_dir, exist_ok=True)

    # Transform ì •ì˜
    transform = A.Compose([
        A.HorizontalFlip(p=0.5) if use_augmentation else A.NoOp(),
        A.RandomBrightnessContrast(p=0.3) if use_augmentation else A.NoOp(),
        A.Resize(img_size[0], img_size[1]),
        ToTensorV2()
    ])

    dataset = RGBHSVDataset_Lite(csv_file, img_size=None, transform=transform)

    brix_all = dataset.data.iloc[:, 1].astype(float).values
    y_bins = _make_stratify_bins(brix_all, n_bins=5)
    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)

    for fold, (tr_idx, va_idx) in enumerate(skf.split(np.arange(len(dataset)), y_bins), start=1):
        print(f"\n Fold {fold}/{k}")

        train_loader = DataLoader(Subset(dataset, tr_idx), batch_size=batch_size, shuffle=True)
        val_loader   = DataLoader(Subset(dataset, va_idx), batch_size=1, shuffle=False)

        model = BrixRegression6CH_Deep().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(10, epochs))
        criterion = nn.SmoothL1Loss()

        for epoch in range(1, epochs + 1):
            # ----- Train -----
            model.train()
            run_loss = 0.0
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                preds = model(images)
                loss = criterion(preds, labels)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                run_loss += loss.item() * images.size(0)

            # ----- Validate -----
            model.eval()
            val_preds, val_trues = [], []
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    out = model(images)
                    val_preds.append(out.item())
                    val_trues.append(float(labels.item()))

            val_mae = mean_absolute_error(val_trues, val_preds)
            print(f"[Fold {fold}][Epoch {epoch}] TrainLoss={run_loss/len(train_loader.dataset):.4f}, ValMAE={val_mae:.4f}")
```

